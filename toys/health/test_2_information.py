"""
Tests for information storage, thread management, and registry operations in the BabyLM system.
Covers memory preferences, sharding, atomic writes, registry updates, and thread relationships.
"""

import numpy as np
import pytest
from unittest.mock import MagicMock

# Import modules from baby package
from baby.information import (
    InformationEngine,
)


# ------------------------------------------------------------------------------
# Information (S2) Processing Tests
# ------------------------------------------------------------------------------


class TestInformationProcessing:
    """Tests for the Information layer (stream processing)"""

    def test_information_engine_init(self):
        """Test InformationEngine initialization"""
        engine = InformationEngine()

        assert engine.stream_pointer == 0
        assert isinstance(engine.output_buffer, bytearray)
        assert len(engine.output_buffer) == 0

    def test_process_stream(self, information_engine, inference_engine):
        """Test processing an input stream"""
        # Create mock update callback
        update_callback = MagicMock()

        # Create test input stream
        test_input = b"Hello, world!"

        # Process the stream
        ciphertext, keystream = information_engine.process_stream(inference_engine, update_callback, test_input)

        # Check output properties
        assert len(ciphertext) == len(test_input)
        assert len(keystream) == len(test_input)

        # Check that update_callback was called for each byte
        assert update_callback.call_count == len(test_input)

        # Check stream pointer was advanced
        assert information_engine.stream_pointer == len(test_input)

    def test_process_generated_bytes(self, information_engine, inference_engine):
        """Test processing generated bytes"""
        # Create mock update callback
        update_callback = MagicMock()

        # Create test bytes
        test_bytes = b"Generated data"

        # Process the bytes
        information_engine.process_generated_bytes(inference_engine, update_callback, test_bytes)

        # Check that update_callback was called for each byte
        assert update_callback.call_count == len(test_bytes)

        # Check stream pointer was advanced
        assert information_engine.stream_pointer == len(test_bytes)

    def test_tensor_to_output_byte(self):
        """Test canonical tensor-to-byte conversion using pattern matching"""
        from baby.inference import InferenceEngine

        engine = InferenceEngine()
        # Create canonical patterns and genome mask
        patterns = np.zeros((256, 48), dtype=np.float32)
        patterns[42] = np.arange(48, dtype=np.float32)  # Make pattern 42 unique
        genome_mask = np.arange(256, dtype=np.uint8)
        # Set tensor to match pattern 42
        T = patterns[42].reshape(4, 2, 3, 2)
        engine.T = T
        engine.F = patterns
        engine.G = genome_mask
        # Should return genome_mask[42]
        output_byte = engine.tensor_to_output_byte()
        assert output_byte == 42


# ------------------------------------------------------------------------------
# Main test runner
# ------------------------------------------------------------------------------

if __name__ == "__main__":
    """Run tests when file is executed directly"""
    pytest.main(["-v", __file__])
