"""
information.py - S2 Information processing for GyroSI Baby LM

This module implements the Information Engine for processing input streams
and generating output streams, representing the Information (S2) layer
of the Common Governance Model.
"""

import numpy as np
from baby.inference import InferenceEngine
from baby.governance import gyrodistance
from typing import Tuple, Callable


def find_closest_pattern_index(T, F):
    """
    Find index of canonical pattern closest to tensor T.
    Args:
        T: Epigenome tensor (any shape that flattens to 48, e.g. (4,2,3,2))
        F: Canonical pattern bank (256, 48)
    Returns:
        int: Index of closest matching pattern (0-255)
    """
    flat_T = T.flatten()
    distances = [gyrodistance(flat_T, pattern) for pattern in F]
    return int(np.argmin(distances))


class InformationEngine:
    """
    Information Engine for processing streams of data

    Manages stream processing, tracking position, and buffering output.
    This engine doesn't make intelligent decisions - it merely processes
    streams according to instructions from the Intelligence layer.
    """

    def __init__(self):
        """Initialize the Information Engine"""
        # Current position in active thread
        self.stream_pointer = 0

        # Accumulator for generated bytes
        self.output_buffer = bytearray()

    def process_stream(
        self,
        inference_engine: InferenceEngine,
        update_callback: Callable[[int, InferenceEngine], None],
        input_stream: bytes,
    ) -> Tuple[bytes, bytes]:
        """
        Process an entire stream of input bytes

        Args:
            inference_engine: The InferenceEngine to use for processing
            update_callback: Function to call for each processed byte (from IntelligenceEngine)
            input_stream: Bytes to process

        Returns:
            Tuple containing:
            - intermediate_ciphertext: Encrypted form of input
            - dynamic_keystream: Generated keystream
        """
        intermediate_ciphertext = bytearray()
        dynamic_keystream = bytearray()

        # Reset stream pointer
        self.stream_pointer = 0

        for P_n in input_stream:
            # 1. Call S3 for pure inference
            key_index = inference_engine.process_byte(P_n)

            # 2. Call update callback (S4) to update state
            update_callback(key_index, inference_engine)

            # 3. Get keystream byte
            keystream_byte = inference_engine.G[key_index]

            # 4. Encrypt the byte
            C_n = P_n ^ keystream_byte
            intermediate_ciphertext.append(C_n)
            dynamic_keystream.append(keystream_byte)

            # 5. Increment stream pointer
            self.stream_pointer += 1

        return bytes(intermediate_ciphertext), bytes(dynamic_keystream)

    def process_generated_bytes(
        self,
        inference_engine: InferenceEngine,
        update_callback: Callable[[int, InferenceEngine], None],
        bytes_to_process: bytes,
    ) -> None:
        """
        Process a sequence of generated bytes (from Intelligence layer)

        This method is used to feed back output bytes into the system,
        ensuring they affect the Epigenome state just like input bytes would.

        Args:
            inference_engine: The InferenceEngine to use
            update_callback: Function to call for each processed byte
            bytes_to_process: Sequence of bytes to process
        """
        for byte in bytes_to_process:
            key_index = inference_engine.process_byte(byte)
            update_callback(key_index, inference_engine)
            self.stream_pointer += 1

    def tensor_to_output_byte(self, T, F, G):
        """
        Canonical tensor-to-byte conversion using epigenome pattern matching.
        This is the only spec-compliant method for deriving a byte from the current tensor state.
        """
        key_index = find_closest_pattern_index(T, F)
        return G[key_index]
